{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1nqfDXvjkNXu4_lP-xfI5-XJqK4C0DTwt",
      "authorship_tag": "ABX9TyNpOXP/SHpgIXFCSb2rqVLI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pmukeshreddy/car_perdication-using-different-architures/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "rwnFK3eaWSjD"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense,Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = [224,224]\n",
        "\n",
        "train_path = \"/content/drive/MyDrive/Colab Notebooks/cardataset/Datasets/Train\"\n",
        "test_path = \"/content/drive/MyDrive/Colab Notebooks/cardataset/Datasets/Test\""
      ],
      "metadata": {
        "id": "Rxki-PYpWXDZ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resenet = ResNet50(input_shape =image_size+[3],weights=\"imagenet\",include_top=False)"
      ],
      "metadata": {
        "id": "AMi8DZKAXKMB"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in resenet.layers:\n",
        "  layer.trainable = False"
      ],
      "metadata": {
        "id": "AAh1PYT5Xbor"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = Flatten()(resenet.output)"
      ],
      "metadata": {
        "id": "rwJI5BZChPxN"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predications = Dense(3,activation=\"softmax\")(x)"
      ],
      "metadata": {
        "id": "gt5qGyzlg51Q"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(inputs=resenet.input,outputs=predications)"
      ],
      "metadata": {
        "id": "2pE2VNX-heoZ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knr9LTnRh198",
        "outputId": "836745c6-8afa-40a1-c3de-30616685548a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1_conv[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_relu (Activation)        (None, 112, 112, 64  0           ['conv1_bn[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_relu[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4160        ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
            "                                                                  'conv2_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block1_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
            "                                                                  'conv2_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block2_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_add (Add)         (None, 56, 56, 256)  0           ['conv2_block2_out[0][0]',       \n",
            "                                                                  'conv2_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block3_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32896       ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
            "                                                                  'conv3_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block1_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
            "                                                                  'conv3_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block2_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_add (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
            "                                                                  'conv3_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block3_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_add (Add)         (None, 28, 28, 512)  0           ['conv3_block3_out[0][0]',       \n",
            "                                                                  'conv3_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block4_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block4_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131328      ['conv3_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv3_block4_out[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
            "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block1_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block1_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
            "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block2_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block2_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_add (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
            "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block3_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block3_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_add (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
            "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block4_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block4_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_add (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
            "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block5_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block5_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block5_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_add (Add)         (None, 14, 14, 1024  0           ['conv4_block5_out[0][0]',       \n",
            "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block6_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block6_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524800      ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
            "                                                                  'conv5_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block1_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
            "                                                                  'conv5_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block2_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
            "                                                                  'conv5_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block3_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 100352)       0           ['conv5_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 3)            301059      ['flatten_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,888,771\n",
            "Trainable params: 301,059\n",
            "Non-trainable params: 23,587,712\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "8qT91xrViiXD"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "iMSJGRa5jZUl"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1/255.0,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)"
      ],
      "metadata": {
        "id": "FtZvO2Pgjlt5"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1/255.0)"
      ],
      "metadata": {
        "id": "bRDQ5idmkJRv"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = train_datagen.flow_from_directory(\"/content/drive/MyDrive/Colab Notebooks/cardataset/Datasets/Train\",target_size=(224,224),batch_size = 32,\n",
        "                                                 class_mode = 'categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBmMdtpQkRej",
        "outputId": "35acef6b-c54c-489d-bc30-1f90b2ea7a6e"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 64 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_set = test_datagen.flow_from_directory(\"/content/drive/MyDrive/Colab Notebooks/cardataset/Datasets/Test\",target_size=(224,224),batch_size = 32,\n",
        "                                                 class_mode = 'categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHYXSMuSkxSl",
        "outputId": "e82b532c-0927-4b46-ec5f-01a691a70dea"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 58 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "steps_per = len(\"/content/drive/MyDrive/Colab Notebooks/cardataset/Datasets/Train\")//32\n",
        "steps_per\n",
        "val_step = len(\"/content/drive/MyDrive/Colab Notebooks/cardataset/Datasets/Test\")//batch_size"
      ],
      "metadata": {
        "id": "3oijgw9Pj2yB"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r = model.fit(training_set,validation_data=test_set,steps_per_epoch=steps_per,epochs=100,validation_steps=val_step)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H76lCKgalC1z",
        "outputId": "d2150f1d-63dd-4117-cc79-689b9866a8c3"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 5s 2s/step - loss: 4.6333 - accuracy: 0.7344 - val_loss: 1.6779 - val_accuracy: 0.5625\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 1s 619ms/step - loss: 1.8507 - accuracy: 0.6250 - val_loss: 5.7648 - val_accuracy: 0.5938\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 1s 608ms/step - loss: 6.9390 - accuracy: 0.6250 - val_loss: 6.2913 - val_accuracy: 0.5000\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 1s 609ms/step - loss: 3.7752 - accuracy: 0.6406 - val_loss: 1.7452 - val_accuracy: 0.5938\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 1s 633ms/step - loss: 0.8326 - accuracy: 0.7500 - val_loss: 5.0513 - val_accuracy: 0.3438\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 1s 620ms/step - loss: 2.9520 - accuracy: 0.4531 - val_loss: 0.6862 - val_accuracy: 0.6562\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 1s 603ms/step - loss: 0.1133 - accuracy: 0.9531 - val_loss: 1.8869 - val_accuracy: 0.5625\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 1s 635ms/step - loss: 1.4517 - accuracy: 0.7344 - val_loss: 2.5997 - val_accuracy: 0.5938\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 1s 620ms/step - loss: 1.2279 - accuracy: 0.7500 - val_loss: 2.1188 - val_accuracy: 0.5625\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 1s 622ms/step - loss: 0.2302 - accuracy: 0.9062 - val_loss: 2.8176 - val_accuracy: 0.5000\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 1s 617ms/step - loss: 0.8867 - accuracy: 0.6875 - val_loss: 2.4875 - val_accuracy: 0.5312\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 1s 602ms/step - loss: 0.4964 - accuracy: 0.7969 - val_loss: 1.2506 - val_accuracy: 0.7812\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 1s 598ms/step - loss: 0.3340 - accuracy: 0.8906 - val_loss: 2.5866 - val_accuracy: 0.5625\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 1s 606ms/step - loss: 0.7310 - accuracy: 0.7969 - val_loss: 1.6567 - val_accuracy: 0.7188\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 1s 622ms/step - loss: 0.3337 - accuracy: 0.8750 - val_loss: 1.2957 - val_accuracy: 0.8125\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 1s 611ms/step - loss: 0.1505 - accuracy: 0.9219 - val_loss: 2.4886 - val_accuracy: 0.5312\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 1s 607ms/step - loss: 0.4581 - accuracy: 0.7500 - val_loss: 1.5226 - val_accuracy: 0.8125\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 1s 603ms/step - loss: 0.0903 - accuracy: 0.9531 - val_loss: 1.3807 - val_accuracy: 0.6562\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 1s 605ms/step - loss: 0.2579 - accuracy: 0.8906 - val_loss: 1.2785 - val_accuracy: 0.7500\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 1s 613ms/step - loss: 0.2369 - accuracy: 0.8750 - val_loss: 1.1240 - val_accuracy: 0.8125\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 1s 617ms/step - loss: 0.0664 - accuracy: 0.9688 - val_loss: 1.6382 - val_accuracy: 0.6875\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 1s 621ms/step - loss: 0.1644 - accuracy: 0.9375 - val_loss: 1.8600 - val_accuracy: 0.6250\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 1s 620ms/step - loss: 0.1185 - accuracy: 0.9375 - val_loss: 1.1056 - val_accuracy: 0.7812\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 1s 618ms/step - loss: 0.0930 - accuracy: 0.9688 - val_loss: 1.3014 - val_accuracy: 0.7188\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 1s 604ms/step - loss: 0.1221 - accuracy: 0.9531 - val_loss: 1.1370 - val_accuracy: 0.7188\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 1s 609ms/step - loss: 0.0688 - accuracy: 0.9844 - val_loss: 1.6293 - val_accuracy: 0.6875\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 1s 603ms/step - loss: 0.0894 - accuracy: 0.9844 - val_loss: 1.6386 - val_accuracy: 0.6875\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 1s 602ms/step - loss: 0.0343 - accuracy: 1.0000 - val_loss: 0.6831 - val_accuracy: 0.7500\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 1s 611ms/step - loss: 0.1008 - accuracy: 0.9688 - val_loss: 0.9528 - val_accuracy: 0.7812\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 1s 602ms/step - loss: 0.0385 - accuracy: 0.9844 - val_loss: 1.3029 - val_accuracy: 0.7812\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 1s 601ms/step - loss: 0.0298 - accuracy: 1.0000 - val_loss: 1.3682 - val_accuracy: 0.7500\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 1s 609ms/step - loss: 0.0372 - accuracy: 1.0000 - val_loss: 0.9702 - val_accuracy: 0.8125\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 1s 619ms/step - loss: 0.0420 - accuracy: 1.0000 - val_loss: 1.4261 - val_accuracy: 0.6875\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 1s 803ms/step - loss: 0.0301 - accuracy: 1.0000 - val_loss: 1.2462 - val_accuracy: 0.7500\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 1s 604ms/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 1.0820 - val_accuracy: 0.7500\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 1s 619ms/step - loss: 0.0421 - accuracy: 0.9844 - val_loss: 0.9207 - val_accuracy: 0.7812\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 1s 600ms/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 1.3083 - val_accuracy: 0.7812\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 1s 605ms/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 1.4775 - val_accuracy: 0.7500\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 1s 642ms/step - loss: 0.0343 - accuracy: 1.0000 - val_loss: 0.8590 - val_accuracy: 0.7500\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 1s 614ms/step - loss: 0.0321 - accuracy: 1.0000 - val_loss: 1.6023 - val_accuracy: 0.7188\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 1s 611ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 1.2640 - val_accuracy: 0.7500\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 1s 609ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 1.4520 - val_accuracy: 0.6875\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 1s 616ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 0.6951 - val_accuracy: 0.8125\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 1s 606ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 1.5224 - val_accuracy: 0.7188\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 1s 609ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 1.0540 - val_accuracy: 0.8438\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 1s 605ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 1.3521 - val_accuracy: 0.7812\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 1s 613ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 1.2096 - val_accuracy: 0.7500\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 1s 610ms/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 0.6460 - val_accuracy: 0.7812\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 1s 588ms/step - loss: 0.0238 - accuracy: 1.0000 - val_loss: 1.4673 - val_accuracy: 0.7188\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 1s 800ms/step - loss: 0.0242 - accuracy: 1.0000 - val_loss: 1.4936 - val_accuracy: 0.7812\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 1s 672ms/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 1.2911 - val_accuracy: 0.8125\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 1s 603ms/step - loss: 0.0260 - accuracy: 1.0000 - val_loss: 0.8236 - val_accuracy: 0.8125\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 1s 609ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.9068 - val_accuracy: 0.7500\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 1s 621ms/step - loss: 0.0278 - accuracy: 1.0000 - val_loss: 0.4761 - val_accuracy: 0.8438\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 1s 600ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.9540 - val_accuracy: 0.8125\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 1s 626ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 1.2222 - val_accuracy: 0.7500\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 1s 611ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 1.0999 - val_accuracy: 0.7812\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 1s 641ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 0.8432 - val_accuracy: 0.8438\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 1s 602ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 1.0595 - val_accuracy: 0.8125\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 1s 610ms/step - loss: 0.0262 - accuracy: 1.0000 - val_loss: 1.2057 - val_accuracy: 0.7812\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 1s 597ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 1.2984 - val_accuracy: 0.7500\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 1s 672ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 1.6476 - val_accuracy: 0.6875\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 1s 610ms/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 1.2189 - val_accuracy: 0.7188\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 1s 645ms/step - loss: 0.0240 - accuracy: 1.0000 - val_loss: 1.0104 - val_accuracy: 0.7188\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 1s 663ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 1.5337 - val_accuracy: 0.6875\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 1s 678ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 1.7062 - val_accuracy: 0.6562\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 1s 621ms/step - loss: 0.0362 - accuracy: 0.9844 - val_loss: 1.3564 - val_accuracy: 0.7500\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 1s 640ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 1.1380 - val_accuracy: 0.7188\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 1s 660ms/step - loss: 0.0344 - accuracy: 1.0000 - val_loss: 0.7560 - val_accuracy: 0.8125\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 1s 684ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.9399 - val_accuracy: 0.8438\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 1s 615ms/step - loss: 0.0233 - accuracy: 1.0000 - val_loss: 0.5778 - val_accuracy: 0.8125\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 1s 611ms/step - loss: 0.0364 - accuracy: 1.0000 - val_loss: 1.0064 - val_accuracy: 0.6875\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 1s 610ms/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 1.5159 - val_accuracy: 0.6562\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 1s 600ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 1.1645 - val_accuracy: 0.7500\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 1s 650ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.6476 - val_accuracy: 0.7812\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 1s 616ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.5587 - val_accuracy: 0.8750\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 1s 611ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 1.2370 - val_accuracy: 0.8438\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 1s 608ms/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 1.5838 - val_accuracy: 0.6875\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 1s 629ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 1.3872 - val_accuracy: 0.7500\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 1s 609ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 1.3302 - val_accuracy: 0.7812\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 1s 606ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 1.2154 - val_accuracy: 0.7188\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 1s 605ms/step - loss: 0.0240 - accuracy: 1.0000 - val_loss: 1.5662 - val_accuracy: 0.7500\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 1s 625ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.8760 - val_accuracy: 0.7500\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 1s 624ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.7921 - val_accuracy: 0.8125\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 1s 602ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 1.3417 - val_accuracy: 0.7812\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 1s 608ms/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 0.3333 - val_accuracy: 0.9375\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 1s 625ms/step - loss: 0.0252 - accuracy: 1.0000 - val_loss: 0.5530 - val_accuracy: 0.8438\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 1s 605ms/step - loss: 0.0284 - accuracy: 1.0000 - val_loss: 1.1354 - val_accuracy: 0.8125\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 1s 607ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 1.0630 - val_accuracy: 0.8438\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 1s 608ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 1.6261 - val_accuracy: 0.7188\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 1s 623ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.8518 - val_accuracy: 0.7500\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 1s 612ms/step - loss: 0.0274 - accuracy: 0.9844 - val_loss: 1.3717 - val_accuracy: 0.7188\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 1s 620ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.9898 - val_accuracy: 0.8438\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 1s 615ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 1.0956 - val_accuracy: 0.8750\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 1s 617ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 0.7456 - val_accuracy: 0.7812\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 1s 626ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.7699 - val_accuracy: 0.8438\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 1s 607ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 1.0333 - val_accuracy: 0.8438\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 1s 602ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 1.0243 - val_accuracy: 0.8438\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 1s 609ms/step - loss: 0.0282 - accuracy: 0.9844 - val_loss: 1.1119 - val_accuracy: 0.7188\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 1s 605ms/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 0.7812 - val_accuracy: 0.8438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import VGG16"
      ],
      "metadata": {
        "id": "yRs-of2elhD6"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16 = VGG16(input_shape=image_size+[3],include_top=False,weights=\"imagenet\")"
      ],
      "metadata": {
        "id": "9lTQUpsNm2_I"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in vgg16.layers:\n",
        "  layer.trainable = False"
      ],
      "metadata": {
        "id": "0bIiqBcLnJ-u"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = Flatten()(vgg16.output)\n",
        "dense = Dense(50,activation=\"relu\")(x)\n",
        "dense2 = Dense(20,activation=\"relu\")(dense)\n",
        "model_vgg16 = Dense(3,activation=\"softmax\")(dense2)"
      ],
      "metadata": {
        "id": "BLhV9BpEnaEC"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16_model = Model(inputs=vgg16.input,outputs=model_vgg16)"
      ],
      "metadata": {
        "id": "Pno7b99zoH4F"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XCsDr3duIoR",
        "outputId": "326eef41-0c23-4b72-ac29-1e190b5be3b1"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 50)                1254450   \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 20)                1020      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 3)                 63        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15,970,221\n",
            "Trainable params: 1,255,533\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16_model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "yXFH0fWWqbeG"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16_model.fit(training_set,validation_data=test_set,epochs=100,steps_per_epoch=steps_per,validation_steps=val_step)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eb7OZIgpPC0",
        "outputId": "aef8fac2-783a-4b31-8c68-d443b797ccf0"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 4s 698ms/step - loss: 1.7482 - accuracy: 0.3281 - val_loss: 1.4410 - val_accuracy: 0.2188\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 1s 659ms/step - loss: 1.1025 - accuracy: 0.3906 - val_loss: 1.0996 - val_accuracy: 0.4688\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 1s 658ms/step - loss: 0.9807 - accuracy: 0.5156 - val_loss: 0.9750 - val_accuracy: 0.5625\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 1s 661ms/step - loss: 0.8201 - accuracy: 0.6250 - val_loss: 0.8020 - val_accuracy: 0.7188\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 1s 676ms/step - loss: 0.6297 - accuracy: 0.7812 - val_loss: 0.7972 - val_accuracy: 0.7188\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 1s 664ms/step - loss: 0.5706 - accuracy: 0.8438 - val_loss: 0.7202 - val_accuracy: 0.7812\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 1s 662ms/step - loss: 0.4370 - accuracy: 0.9219 - val_loss: 0.5847 - val_accuracy: 0.8125\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 1s 668ms/step - loss: 0.3950 - accuracy: 0.9219 - val_loss: 0.6453 - val_accuracy: 0.7500\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 1s 670ms/step - loss: 0.3368 - accuracy: 0.9375 - val_loss: 0.7490 - val_accuracy: 0.6562\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 1s 676ms/step - loss: 0.2777 - accuracy: 0.9531 - val_loss: 0.5031 - val_accuracy: 0.8125\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 1s 658ms/step - loss: 0.2210 - accuracy: 1.0000 - val_loss: 0.4527 - val_accuracy: 0.8438\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 1s 661ms/step - loss: 0.1978 - accuracy: 0.9688 - val_loss: 0.4715 - val_accuracy: 0.7812\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 1s 657ms/step - loss: 0.1741 - accuracy: 0.9844 - val_loss: 0.4445 - val_accuracy: 0.8438\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 1s 662ms/step - loss: 0.1564 - accuracy: 0.9844 - val_loss: 0.4666 - val_accuracy: 0.7812\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 1s 669ms/step - loss: 0.1289 - accuracy: 0.9844 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 1s 668ms/step - loss: 0.1189 - accuracy: 0.9844 - val_loss: 0.4802 - val_accuracy: 0.7188\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 1s 658ms/step - loss: 0.0916 - accuracy: 0.9844 - val_loss: 0.4428 - val_accuracy: 0.7812\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 1s 666ms/step - loss: 0.0657 - accuracy: 1.0000 - val_loss: 0.3618 - val_accuracy: 0.8750\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 1s 668ms/step - loss: 0.0553 - accuracy: 1.0000 - val_loss: 0.4176 - val_accuracy: 0.8438\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 1s 662ms/step - loss: 0.0552 - accuracy: 1.0000 - val_loss: 0.4186 - val_accuracy: 0.8438\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 1s 679ms/step - loss: 0.0376 - accuracy: 1.0000 - val_loss: 0.2934 - val_accuracy: 0.9062\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 1s 659ms/step - loss: 0.0378 - accuracy: 1.0000 - val_loss: 0.5557 - val_accuracy: 0.8125\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 1s 660ms/step - loss: 0.0363 - accuracy: 1.0000 - val_loss: 0.4502 - val_accuracy: 0.7500\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 1s 672ms/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 0.4830 - val_accuracy: 0.7812\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 1s 673ms/step - loss: 0.0269 - accuracy: 1.0000 - val_loss: 0.2856 - val_accuracy: 0.8750\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 1s 680ms/step - loss: 0.0245 - accuracy: 1.0000 - val_loss: 0.4045 - val_accuracy: 0.8438\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 1s 667ms/step - loss: 0.0271 - accuracy: 1.0000 - val_loss: 0.1872 - val_accuracy: 0.9375\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 1s 698ms/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 0.3530 - val_accuracy: 0.8750\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 1s 674ms/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 0.3965 - val_accuracy: 0.8438\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 1s 674ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.2860 - val_accuracy: 0.8750\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 1s 659ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.3380 - val_accuracy: 0.8750\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 1s 672ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.1980 - val_accuracy: 0.9688\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 1s 674ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.4866 - val_accuracy: 0.7812\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 1s 675ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.3888 - val_accuracy: 0.8438\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 1s 667ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.4413 - val_accuracy: 0.8125\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 1s 663ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.2604 - val_accuracy: 0.9062\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 1s 662ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.4400 - val_accuracy: 0.8438\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 1s 655ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.1929 - val_accuracy: 0.9375\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 1s 660ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.3595 - val_accuracy: 0.8438\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 1s 685ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.2714 - val_accuracy: 0.9062\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 1s 665ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.4933 - val_accuracy: 0.7812\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 1s 661ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.3434 - val_accuracy: 0.8750\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 1s 667ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.2879 - val_accuracy: 0.8750\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 1s 654ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.3900 - val_accuracy: 0.8438\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 1s 669ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.4457 - val_accuracy: 0.8125\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 1s 656ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.4009 - val_accuracy: 0.8438\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 1s 666ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.3803 - val_accuracy: 0.8125\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 1s 671ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.2490 - val_accuracy: 0.9375\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 1s 664ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.4161 - val_accuracy: 0.8750\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 1s 664ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.2165 - val_accuracy: 0.9062\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 1s 670ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.3770 - val_accuracy: 0.8750\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 1s 665ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.2349 - val_accuracy: 0.9375\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 1s 673ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.3732 - val_accuracy: 0.8750\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 1s 667ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.3188 - val_accuracy: 0.8438\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 1s 671ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.2319 - val_accuracy: 0.9062\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 1s 665ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.2043 - val_accuracy: 0.9375\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 1s 690ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.4028 - val_accuracy: 0.8125\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 1s 708ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.4425 - val_accuracy: 0.8125\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 1s 682ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.2192 - val_accuracy: 0.9062\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 1s 673ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.3944 - val_accuracy: 0.8438\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 1s 676ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.4185 - val_accuracy: 0.8750\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 1s 689ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.2277 - val_accuracy: 0.9375\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 1s 661ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.3473 - val_accuracy: 0.8750\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 1s 697ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.4445 - val_accuracy: 0.8125\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 1s 674ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.3343 - val_accuracy: 0.9062\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 1s 681ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.3176 - val_accuracy: 0.8750\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 1s 669ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.2312 - val_accuracy: 0.9062\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 1s 668ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.4906 - val_accuracy: 0.7500\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 1s 672ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.3496 - val_accuracy: 0.8750\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 1s 677ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.3758 - val_accuracy: 0.8438\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 1s 658ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.3263 - val_accuracy: 0.8750\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 1s 677ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.4755 - val_accuracy: 0.7812\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 1s 672ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2091 - val_accuracy: 0.9062\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 1s 664ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.3879 - val_accuracy: 0.8438\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 1s 661ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2673 - val_accuracy: 0.9062\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 1s 673ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.3720 - val_accuracy: 0.8750\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 1s 687ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.4014 - val_accuracy: 0.8438\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 1s 685ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.4323 - val_accuracy: 0.8438\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 1s 666ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.2404 - val_accuracy: 0.9062\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 1s 688ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.3429 - val_accuracy: 0.8750\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 1s 661ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.3301 - val_accuracy: 0.8438\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 1s 672ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.4082 - val_accuracy: 0.8125\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 1s 671ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2917 - val_accuracy: 0.8125\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 1s 693ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2080 - val_accuracy: 0.9062\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 1s 689ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.4321 - val_accuracy: 0.8438\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 1s 689ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.3311 - val_accuracy: 0.8125\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 1s 711ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2161 - val_accuracy: 0.9375\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 1s 692ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3245 - val_accuracy: 0.8438\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 1s 679ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1590 - val_accuracy: 0.9688\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 1s 680ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2414 - val_accuracy: 0.8750\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 1s 671ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2977 - val_accuracy: 0.8750\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 1s 673ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2292 - val_accuracy: 0.9375\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 1s 670ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4256 - val_accuracy: 0.8125\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 1s 643ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2004 - val_accuracy: 0.9375\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 1s 664ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1146 - val_accuracy: 0.9688\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 1s 668ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3296 - val_accuracy: 0.8750\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 1s 667ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1967 - val_accuracy: 0.9375\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 1s 665ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3797 - val_accuracy: 0.8750\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 1s 664ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2786 - val_accuracy: 0.9375\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 1s 667ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1411 - val_accuracy: 0.9375\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f12be1fa040>"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications import InceptionV3"
      ],
      "metadata": {
        "id": "wQnWHDrSqTCD"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inception = InceptionV3(weights=\"imagenet\",include_top=False,input_shape=image_size+[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJ8zEj9FsghB",
        "outputId": "caee6506-cac9-472f-d094-7483744b5ccb"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in inception.layers:\n",
        "  layer.trainable = False"
      ],
      "metadata": {
        "id": "iFBzXNMVtFtr"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = Flatten()(inception.output)\n",
        "dense = Dense(50,activation=\"relu\")(x)\n",
        "dense2 = Dense(20,activation=\"relu\")(dense)\n",
        "model_inception = Dense(3,activation=\"softmax\")(dense2)"
      ],
      "metadata": {
        "id": "mB4p2zTMr0l9"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inception_model = Model(inputs=inception.input,outputs=model_inception)"
      ],
      "metadata": {
        "id": "HVBHElN_sGLJ"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inception_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1qZdk8YuDYT",
        "outputId": "03bae1b6-4937-42ef-fcc0-1d57dd566379"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_7 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 111, 111, 32  864         ['input_7[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 111, 111, 32  96         ['conv2d[0][0]']                 \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 111, 111, 32  0           ['batch_normalization[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 109, 109, 32  9216        ['activation[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 109, 109, 32  96         ['conv2d_1[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 109, 109, 32  0           ['batch_normalization_1[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 109, 109, 64  18432       ['activation_1[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 109, 109, 64  192        ['conv2d_2[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 109, 109, 64  0           ['batch_normalization_2[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 54, 54, 64)   0           ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 54, 54, 80)   5120        ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 54, 54, 80)  240         ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 54, 54, 80)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 52, 52, 192)  138240      ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 52, 52, 192)  576        ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 52, 52, 192)  0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 25, 25, 192)  0          ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 25, 25, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 25, 25, 64)  192         ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 25, 25, 64)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 25, 25, 48)   9216        ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 25, 25, 96)   55296       ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 25, 25, 48)  144         ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 25, 25, 96)  288         ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 25, 25, 48)   0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 25, 25, 96)   0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 25, 25, 192)  0          ['max_pooling2d_1[0][0]']        \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 25, 25, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 25, 25, 64)   76800       ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 25, 25, 96)   82944       ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 25, 25, 32)   6144        ['average_pooling2d[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 25, 25, 64)  192         ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 25, 25, 64)  192         ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 25, 25, 96)  288         ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 25, 25, 32)  96          ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 25, 25, 64)   0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 25, 25, 64)   0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 25, 25, 32)   0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " mixed0 (Concatenate)           (None, 25, 25, 256)  0           ['activation_5[0][0]',           \n",
            "                                                                  'activation_7[0][0]',           \n",
            "                                                                  'activation_10[0][0]',          \n",
            "                                                                  'activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 25, 25, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 25, 25, 64)  192         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 25, 25, 48)   12288       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 25, 25, 96)   55296       ['activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 25, 25, 48)  144         ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 25, 25, 96)  288         ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 25, 25, 48)   0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_1 (AveragePo  (None, 25, 25, 256)  0          ['mixed0[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 25, 25, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 25, 25, 64)   76800       ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 25, 25, 96)   82944       ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 25, 25, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 25, 25, 64)  192         ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 25, 25, 64)  192         ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 25, 25, 96)  288         ['conv2d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 25, 25, 64)  192         ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " mixed1 (Concatenate)           (None, 25, 25, 288)  0           ['activation_12[0][0]',          \n",
            "                                                                  'activation_14[0][0]',          \n",
            "                                                                  'activation_17[0][0]',          \n",
            "                                                                  'activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 25, 25, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 25, 25, 64)  192         ['conv2d_22[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 25, 25, 48)   13824       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 25, 25, 96)   55296       ['activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 25, 25, 48)  144         ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 25, 25, 96)  288         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 25, 25, 48)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_2 (AveragePo  (None, 25, 25, 288)  0          ['mixed1[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 25, 25, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 25, 25, 64)   76800       ['activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 25, 25, 96)   82944       ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 25, 25, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 25, 25, 64)  192         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 25, 25, 64)  192         ['conv2d_21[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 25, 25, 96)  288         ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 25, 25, 64)  192         ['conv2d_25[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " mixed2 (Concatenate)           (None, 25, 25, 288)  0           ['activation_19[0][0]',          \n",
            "                                                                  'activation_21[0][0]',          \n",
            "                                                                  'activation_24[0][0]',          \n",
            "                                                                  'activation_25[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 25, 25, 64)   18432       ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 25, 25, 64)  192         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 25, 25, 96)   55296       ['activation_27[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 25, 25, 96)  288         ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 12, 12, 384)  995328      ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 12, 12, 96)   82944       ['activation_28[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 12, 12, 384)  1152       ['conv2d_26[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 12, 12, 96)  288         ['conv2d_29[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 12, 12, 384)  0           ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 12, 12, 96)   0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 12, 12, 288)  0          ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " mixed3 (Concatenate)           (None, 12, 12, 768)  0           ['activation_26[0][0]',          \n",
            "                                                                  'activation_29[0][0]',          \n",
            "                                                                  'max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 12, 12, 128)  98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 12, 12, 128)  384        ['conv2d_34[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_34 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_34[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 12, 12, 128)  384        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_35 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 12, 12, 128)  98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_35[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 12, 12, 128)  384        ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 12, 12, 128)  384        ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " activation_36 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_31[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_36[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 12, 12, 128)  384        ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 12, 12, 128)  384        ['conv2d_37[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_32 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " activation_37 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_3 (AveragePo  (None, 12, 12, 768)  0          ['mixed3[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 12, 12, 192)  172032      ['activation_32[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 12, 12, 192)  172032      ['activation_37[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_3[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 12, 12, 192)  576        ['conv2d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 12, 12, 192)  576        ['conv2d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 12, 12, 192)  576        ['conv2d_38[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 12, 12, 192)  576        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " activation_33 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " activation_38 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " activation_39 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " mixed4 (Concatenate)           (None, 12, 12, 768)  0           ['activation_30[0][0]',          \n",
            "                                                                  'activation_33[0][0]',          \n",
            "                                                                  'activation_38[0][0]',          \n",
            "                                                                  'activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 12, 12, 160)  480        ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_44 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_44[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 12, 12, 160)  480        ['conv2d_45[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_45 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_45[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 12, 12, 160)  480        ['conv2d_41[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 12, 12, 160)  480        ['conv2d_46[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_41 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " activation_46 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_41[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_46[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 12, 12, 160)  480        ['conv2d_42[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 12, 12, 160)  480        ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_42 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " activation_47 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_4 (AveragePo  (None, 12, 12, 768)  0          ['mixed4[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_42[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_47[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_4[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 12, 12, 192)  576        ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 12, 12, 192)  576        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 12, 12, 192)  576        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 12, 12, 192)  576        ['conv2d_49[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_40 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " activation_43 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " activation_48 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            " activation_49 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_49[0][0]'] \n",
            "                                                                                                  \n",
            " mixed5 (Concatenate)           (None, 12, 12, 768)  0           ['activation_40[0][0]',          \n",
            "                                                                  'activation_43[0][0]',          \n",
            "                                                                  'activation_48[0][0]',          \n",
            "                                                                  'activation_49[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_54 (BatchN  (None, 12, 12, 160)  480        ['conv2d_54[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_54 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_54[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_54[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_55 (BatchN  (None, 12, 12, 160)  480        ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_55 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_55[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_55[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 12, 12, 160)  480        ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_56 (BatchN  (None, 12, 12, 160)  480        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_51 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_51[0][0]'] \n",
            "                                                                                                  \n",
            " activation_56 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_56[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_51[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_56[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 12, 12, 160)  480        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_57 (BatchN  (None, 12, 12, 160)  480        ['conv2d_57[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_52 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_52[0][0]'] \n",
            "                                                                                                  \n",
            " activation_57 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_57[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_5 (AveragePo  (None, 12, 12, 768)  0          ['mixed5[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_52[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_57[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_5[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 12, 12, 192)  576        ['conv2d_50[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_53 (BatchN  (None, 12, 12, 192)  576        ['conv2d_53[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_58 (BatchN  (None, 12, 12, 192)  576        ['conv2d_58[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_59 (BatchN  (None, 12, 12, 192)  576        ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_50 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_50[0][0]'] \n",
            "                                                                                                  \n",
            " activation_53 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_53[0][0]'] \n",
            "                                                                                                  \n",
            " activation_58 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_58[0][0]'] \n",
            "                                                                                                  \n",
            " activation_59 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_59[0][0]'] \n",
            "                                                                                                  \n",
            " mixed6 (Concatenate)           (None, 12, 12, 768)  0           ['activation_50[0][0]',          \n",
            "                                                                  'activation_53[0][0]',          \n",
            "                                                                  'activation_58[0][0]',          \n",
            "                                                                  'activation_59[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_64 (BatchN  (None, 12, 12, 192)  576        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_64 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_64[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_64[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_65 (BatchN  (None, 12, 12, 192)  576        ['conv2d_65[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_65 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_65[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_65[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_61 (BatchN  (None, 12, 12, 192)  576        ['conv2d_61[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_66 (BatchN  (None, 12, 12, 192)  576        ['conv2d_66[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_61 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_61[0][0]'] \n",
            "                                                                                                  \n",
            " activation_66 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_66[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_61[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_66[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_62 (BatchN  (None, 12, 12, 192)  576        ['conv2d_62[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_67 (BatchN  (None, 12, 12, 192)  576        ['conv2d_67[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_62 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_62[0][0]'] \n",
            "                                                                                                  \n",
            " activation_67 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_67[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_6 (AveragePo  (None, 12, 12, 768)  0          ['mixed6[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_62[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_67[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_6[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_60 (BatchN  (None, 12, 12, 192)  576        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_63 (BatchN  (None, 12, 12, 192)  576        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_68 (BatchN  (None, 12, 12, 192)  576        ['conv2d_68[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_69 (BatchN  (None, 12, 12, 192)  576        ['conv2d_69[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_60 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " activation_63 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_63[0][0]'] \n",
            "                                                                                                  \n",
            " activation_68 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_68[0][0]'] \n",
            "                                                                                                  \n",
            " activation_69 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_69[0][0]'] \n",
            "                                                                                                  \n",
            " mixed7 (Concatenate)           (None, 12, 12, 768)  0           ['activation_60[0][0]',          \n",
            "                                                                  'activation_63[0][0]',          \n",
            "                                                                  'activation_68[0][0]',          \n",
            "                                                                  'activation_69[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_72 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_72 (BatchN  (None, 12, 12, 192)  576        ['conv2d_72[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_72 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_72[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_73 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_72[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_73 (BatchN  (None, 12, 12, 192)  576        ['conv2d_73[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_73 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_73[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_74 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_73[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_70 (BatchN  (None, 12, 12, 192)  576        ['conv2d_70[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_74 (BatchN  (None, 12, 12, 192)  576        ['conv2d_74[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_70 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_70[0][0]'] \n",
            "                                                                                                  \n",
            " activation_74 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_74[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)             (None, 5, 5, 320)    552960      ['activation_70[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_75 (Conv2D)             (None, 5, 5, 192)    331776      ['activation_74[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_71 (BatchN  (None, 5, 5, 320)   960         ['conv2d_71[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_75 (BatchN  (None, 5, 5, 192)   576         ['conv2d_75[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_71 (Activation)     (None, 5, 5, 320)    0           ['batch_normalization_71[0][0]'] \n",
            "                                                                                                  \n",
            " activation_75 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_75[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 768)   0           ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " mixed8 (Concatenate)           (None, 5, 5, 1280)   0           ['activation_71[0][0]',          \n",
            "                                                                  'activation_75[0][0]',          \n",
            "                                                                  'max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_80 (Conv2D)             (None, 5, 5, 448)    573440      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_80 (BatchN  (None, 5, 5, 448)   1344        ['conv2d_80[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_80 (Activation)     (None, 5, 5, 448)    0           ['batch_normalization_80[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_77 (Conv2D)             (None, 5, 5, 384)    491520      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_81 (Conv2D)             (None, 5, 5, 384)    1548288     ['activation_80[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_77 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_77[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_81 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_81[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_77 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_77[0][0]'] \n",
            "                                                                                                  \n",
            " activation_81 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_81[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_78 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_77[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_79 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_77[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_82 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_81[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_83 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_81[0][0]']          \n",
            "                                                                                                  \n",
            " average_pooling2d_7 (AveragePo  (None, 5, 5, 1280)  0           ['mixed8[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_76 (Conv2D)             (None, 5, 5, 320)    409600      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_78 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_78[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_79 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_79[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_82 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_82[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_83 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_83[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_84 (Conv2D)             (None, 5, 5, 192)    245760      ['average_pooling2d_7[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_76 (BatchN  (None, 5, 5, 320)   960         ['conv2d_76[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_78 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_78[0][0]'] \n",
            "                                                                                                  \n",
            " activation_79 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_79[0][0]'] \n",
            "                                                                                                  \n",
            " activation_82 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_82[0][0]'] \n",
            "                                                                                                  \n",
            " activation_83 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_83[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_84 (BatchN  (None, 5, 5, 192)   576         ['conv2d_84[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_76 (Activation)     (None, 5, 5, 320)    0           ['batch_normalization_76[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9_0 (Concatenate)         (None, 5, 5, 768)    0           ['activation_78[0][0]',          \n",
            "                                                                  'activation_79[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 5, 5, 768)    0           ['activation_82[0][0]',          \n",
            "                                                                  'activation_83[0][0]']          \n",
            "                                                                                                  \n",
            " activation_84 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_84[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9 (Concatenate)           (None, 5, 5, 2048)   0           ['activation_76[0][0]',          \n",
            "                                                                  'mixed9_0[0][0]',               \n",
            "                                                                  'concatenate[0][0]',            \n",
            "                                                                  'activation_84[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_89 (Conv2D)             (None, 5, 5, 448)    917504      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_89 (BatchN  (None, 5, 5, 448)   1344        ['conv2d_89[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_89 (Activation)     (None, 5, 5, 448)    0           ['batch_normalization_89[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_86 (Conv2D)             (None, 5, 5, 384)    786432      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_90 (Conv2D)             (None, 5, 5, 384)    1548288     ['activation_89[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_86 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_86[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_90 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_90[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_86 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_86[0][0]'] \n",
            "                                                                                                  \n",
            " activation_90 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_90[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_87 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_86[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_88 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_86[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_91 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_90[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_92 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_90[0][0]']          \n",
            "                                                                                                  \n",
            " average_pooling2d_8 (AveragePo  (None, 5, 5, 2048)  0           ['mixed9[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_85 (Conv2D)             (None, 5, 5, 320)    655360      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_87 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_87[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_88 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_88[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_91 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_91[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_92 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_92[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_93 (Conv2D)             (None, 5, 5, 192)    393216      ['average_pooling2d_8[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_85 (BatchN  (None, 5, 5, 320)   960         ['conv2d_85[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_87 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_87[0][0]'] \n",
            "                                                                                                  \n",
            " activation_88 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_88[0][0]'] \n",
            "                                                                                                  \n",
            " activation_91 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_91[0][0]'] \n",
            "                                                                                                  \n",
            " activation_92 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_92[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_93 (BatchN  (None, 5, 5, 192)   576         ['conv2d_93[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_85 (Activation)     (None, 5, 5, 320)    0           ['batch_normalization_85[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9_1 (Concatenate)         (None, 5, 5, 768)    0           ['activation_87[0][0]',          \n",
            "                                                                  'activation_88[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 5, 5, 768)    0           ['activation_91[0][0]',          \n",
            "                                                                  'activation_92[0][0]']          \n",
            "                                                                                                  \n",
            " activation_93 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_93[0][0]'] \n",
            "                                                                                                  \n",
            " mixed10 (Concatenate)          (None, 5, 5, 2048)   0           ['activation_85[0][0]',          \n",
            "                                                                  'mixed9_1[0][0]',               \n",
            "                                                                  'concatenate_1[0][0]',          \n",
            "                                                                  'activation_93[0][0]']          \n",
            "                                                                                                  \n",
            " flatten_6 (Flatten)            (None, 51200)        0           ['mixed10[0][0]']                \n",
            "                                                                                                  \n",
            " dense_14 (Dense)               (None, 50)           2560050     ['flatten_6[0][0]']              \n",
            "                                                                                                  \n",
            " dense_15 (Dense)               (None, 20)           1020        ['dense_14[0][0]']               \n",
            "                                                                                                  \n",
            " dense_16 (Dense)               (None, 3)            63          ['dense_15[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 24,363,917\n",
            "Trainable params: 2,561,133\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inception_model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "EQ_Ann0IsYn8"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inception_model.fit(training_set,validation_data=test_set,epochs=100,steps_per_epoch=steps_per,validation_steps=val_step)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyTqx7getUEx",
        "outputId": "84ef6910-16f0-4e4d-a0db-cb6db2d1f689"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 7s 1s/step - loss: 1.9879 - accuracy: 0.4844 - val_loss: 9.7709 - val_accuracy: 0.5625\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 1s 603ms/step - loss: 8.0169 - accuracy: 0.4844 - val_loss: 2.5426 - val_accuracy: 0.4062\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 1s 604ms/step - loss: 2.2130 - accuracy: 0.5938 - val_loss: 1.5674 - val_accuracy: 0.5938\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 1s 590ms/step - loss: 0.4325 - accuracy: 0.8750 - val_loss: 1.0894 - val_accuracy: 0.7500\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 1s 593ms/step - loss: 1.1199 - accuracy: 0.8438 - val_loss: 0.8417 - val_accuracy: 0.8438\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 1s 619ms/step - loss: 0.3738 - accuracy: 0.8594 - val_loss: 1.1586 - val_accuracy: 0.9062\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 1s 601ms/step - loss: 0.6353 - accuracy: 0.8906 - val_loss: 1.5396 - val_accuracy: 0.8125\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 1s 607ms/step - loss: 0.0578 - accuracy: 0.9688 - val_loss: 0.6477 - val_accuracy: 0.7500\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 1s 587ms/step - loss: 0.1407 - accuracy: 0.9688 - val_loss: 0.9128 - val_accuracy: 0.8125\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 1s 596ms/step - loss: 0.1992 - accuracy: 0.9375 - val_loss: 0.7786 - val_accuracy: 0.7812\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 1s 618ms/step - loss: 0.0425 - accuracy: 0.9688 - val_loss: 1.0638 - val_accuracy: 0.8125\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 1s 579ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.4821 - val_accuracy: 0.8125\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 1s 612ms/step - loss: 0.0247 - accuracy: 0.9844 - val_loss: 1.4572 - val_accuracy: 0.8125\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 1s 614ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.6081 - val_accuracy: 0.8750\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 1s 591ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.8083 - val_accuracy: 0.9062\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 1s 610ms/step - loss: 0.1157 - accuracy: 0.9688 - val_loss: 1.5001 - val_accuracy: 0.8750\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 1s 595ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.2543 - val_accuracy: 0.8750\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 1s 591ms/step - loss: 0.0845 - accuracy: 0.9844 - val_loss: 0.9413 - val_accuracy: 0.8438\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 1s 609ms/step - loss: 6.5256e-04 - accuracy: 1.0000 - val_loss: 0.9691 - val_accuracy: 0.8125\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 1s 602ms/step - loss: 0.0388 - accuracy: 0.9844 - val_loss: 0.8766 - val_accuracy: 0.6562\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 1s 601ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 1.2815 - val_accuracy: 0.7188\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 1s 605ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.3906 - val_accuracy: 0.7500\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 1s 596ms/step - loss: 0.1106 - accuracy: 0.9531 - val_loss: 1.1424 - val_accuracy: 0.7812\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 1s 606ms/step - loss: 5.9420e-04 - accuracy: 1.0000 - val_loss: 1.5062 - val_accuracy: 0.6875\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 1s 583ms/step - loss: 1.1364e-04 - accuracy: 1.0000 - val_loss: 1.4056 - val_accuracy: 0.8125\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 1s 595ms/step - loss: 6.3598e-04 - accuracy: 1.0000 - val_loss: 2.0576 - val_accuracy: 0.7812\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 1s 613ms/step - loss: 0.0195 - accuracy: 0.9844 - val_loss: 1.0189 - val_accuracy: 0.8750\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 1s 587ms/step - loss: 0.0129 - accuracy: 0.9844 - val_loss: 1.1989 - val_accuracy: 0.8438\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 1s 598ms/step - loss: 0.0181 - accuracy: 0.9844 - val_loss: 0.8005 - val_accuracy: 0.8750\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 1s 613ms/step - loss: 2.0018e-05 - accuracy: 1.0000 - val_loss: 1.4139 - val_accuracy: 0.7812\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 1s 604ms/step - loss: 9.9371e-04 - accuracy: 1.0000 - val_loss: 0.8538 - val_accuracy: 0.8438\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 1s 601ms/step - loss: 0.0180 - accuracy: 0.9844 - val_loss: 0.7285 - val_accuracy: 0.8438\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 1s 597ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.1281 - val_accuracy: 0.8125\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 1s 603ms/step - loss: 2.2639e-04 - accuracy: 1.0000 - val_loss: 1.7329 - val_accuracy: 0.7188\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 1s 605ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.7749 - val_accuracy: 0.7188\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 1s 628ms/step - loss: 0.0382 - accuracy: 0.9688 - val_loss: 1.6383 - val_accuracy: 0.7188\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 1s 630ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.1761 - val_accuracy: 0.8125\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 1s 611ms/step - loss: 1.3894e-04 - accuracy: 1.0000 - val_loss: 1.4780 - val_accuracy: 0.7812\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 1s 616ms/step - loss: 8.3557e-05 - accuracy: 1.0000 - val_loss: 1.4273 - val_accuracy: 0.8125\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 1s 618ms/step - loss: 6.1816e-05 - accuracy: 1.0000 - val_loss: 0.5422 - val_accuracy: 0.9062\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 1s 598ms/step - loss: 9.0575e-04 - accuracy: 1.0000 - val_loss: 2.0181 - val_accuracy: 0.7500\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 1s 596ms/step - loss: 0.0426 - accuracy: 0.9844 - val_loss: 1.8109 - val_accuracy: 0.8125\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 1s 611ms/step - loss: 8.7955e-04 - accuracy: 1.0000 - val_loss: 1.5723 - val_accuracy: 0.8125\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 1s 591ms/step - loss: 4.2218e-04 - accuracy: 1.0000 - val_loss: 1.2472 - val_accuracy: 0.7812\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 1s 610ms/step - loss: 3.1233e-04 - accuracy: 1.0000 - val_loss: 0.1470 - val_accuracy: 0.9375\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 1s 592ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.3557 - val_accuracy: 0.7188\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 1s 597ms/step - loss: 4.8266e-05 - accuracy: 1.0000 - val_loss: 0.6813 - val_accuracy: 0.8750\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 1s 650ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.2354 - val_accuracy: 0.7500\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 1s 599ms/step - loss: 8.1484e-06 - accuracy: 1.0000 - val_loss: 0.2203 - val_accuracy: 0.8750\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 1s 584ms/step - loss: 4.9570e-05 - accuracy: 1.0000 - val_loss: 0.3930 - val_accuracy: 0.7812\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 1s 601ms/step - loss: 1.9669e-04 - accuracy: 1.0000 - val_loss: 1.2913 - val_accuracy: 0.7188\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 1s 597ms/step - loss: 4.2596e-06 - accuracy: 1.0000 - val_loss: 1.3647 - val_accuracy: 0.8125\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 1s 586ms/step - loss: 3.0797e-04 - accuracy: 1.0000 - val_loss: 0.6248 - val_accuracy: 0.8750\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 1s 594ms/step - loss: 4.4983e-05 - accuracy: 1.0000 - val_loss: 1.0438 - val_accuracy: 0.7500\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 1s 598ms/step - loss: 2.3550e-05 - accuracy: 1.0000 - val_loss: 1.3357 - val_accuracy: 0.7812\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 1s 584ms/step - loss: 2.9259e-05 - accuracy: 1.0000 - val_loss: 1.2217 - val_accuracy: 0.7812\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 1s 590ms/step - loss: 1.9949e-04 - accuracy: 1.0000 - val_loss: 1.0939 - val_accuracy: 0.7812\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 1s 593ms/step - loss: 4.4615e-05 - accuracy: 1.0000 - val_loss: 0.7343 - val_accuracy: 0.7812\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 1s 591ms/step - loss: 1.5045e-05 - accuracy: 1.0000 - val_loss: 0.8176 - val_accuracy: 0.8438\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 1s 615ms/step - loss: 5.6529e-06 - accuracy: 1.0000 - val_loss: 1.4016 - val_accuracy: 0.8125\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 1s 776ms/step - loss: 1.0013e-05 - accuracy: 1.0000 - val_loss: 1.0401 - val_accuracy: 0.7812\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 1s 787ms/step - loss: 3.7177e-06 - accuracy: 1.0000 - val_loss: 0.6070 - val_accuracy: 0.8438\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 1s 626ms/step - loss: 2.1151e-04 - accuracy: 1.0000 - val_loss: 1.0813 - val_accuracy: 0.8125\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 1s 617ms/step - loss: 3.6711e-06 - accuracy: 1.0000 - val_loss: 1.8524 - val_accuracy: 0.6875\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 1s 631ms/step - loss: 2.4154e-05 - accuracy: 1.0000 - val_loss: 1.6012 - val_accuracy: 0.7188\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 1s 610ms/step - loss: 2.2063e-05 - accuracy: 1.0000 - val_loss: 0.9718 - val_accuracy: 0.7812\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 1s 624ms/step - loss: 1.8067e-06 - accuracy: 1.0000 - val_loss: 0.9709 - val_accuracy: 0.7500\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 1s 629ms/step - loss: 8.7357e-07 - accuracy: 1.0000 - val_loss: 1.1452 - val_accuracy: 0.8125\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 1s 610ms/step - loss: 4.5781e-04 - accuracy: 1.0000 - val_loss: 0.6711 - val_accuracy: 0.8438\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 1s 633ms/step - loss: 2.1526e-05 - accuracy: 1.0000 - val_loss: 1.2641 - val_accuracy: 0.8438\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 1s 663ms/step - loss: 9.9092e-07 - accuracy: 1.0000 - val_loss: 0.4130 - val_accuracy: 0.8750\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 1s 614ms/step - loss: 1.1818e-05 - accuracy: 1.0000 - val_loss: 1.0894 - val_accuracy: 0.7812\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 1s 651ms/step - loss: 3.5501e-06 - accuracy: 1.0000 - val_loss: 0.9731 - val_accuracy: 0.8750\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 1s 607ms/step - loss: 1.3625e-04 - accuracy: 1.0000 - val_loss: 0.5834 - val_accuracy: 0.8438\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 1s 615ms/step - loss: 1.2498e-06 - accuracy: 1.0000 - val_loss: 1.1521 - val_accuracy: 0.8125\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 1s 645ms/step - loss: 3.2209e-04 - accuracy: 1.0000 - val_loss: 1.3160 - val_accuracy: 0.7500\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 1s 591ms/step - loss: 1.1027e-06 - accuracy: 1.0000 - val_loss: 0.6322 - val_accuracy: 0.7812\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 1s 599ms/step - loss: 3.9617e-05 - accuracy: 1.0000 - val_loss: 0.5461 - val_accuracy: 0.8750\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 1s 600ms/step - loss: 2.1271e-06 - accuracy: 1.0000 - val_loss: 1.0609 - val_accuracy: 0.8125\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 1s 594ms/step - loss: 1.4660e-05 - accuracy: 1.0000 - val_loss: 0.5917 - val_accuracy: 0.8438\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 1s 625ms/step - loss: 5.6564e-06 - accuracy: 1.0000 - val_loss: 0.4297 - val_accuracy: 0.8750\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 1s 594ms/step - loss: 1.2088e-06 - accuracy: 1.0000 - val_loss: 0.9226 - val_accuracy: 0.8125\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 1s 606ms/step - loss: 3.0763e-05 - accuracy: 1.0000 - val_loss: 0.6843 - val_accuracy: 0.8438\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 1s 588ms/step - loss: 2.2441e-04 - accuracy: 1.0000 - val_loss: 0.6868 - val_accuracy: 0.8438\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 1s 624ms/step - loss: 2.5461e-06 - accuracy: 1.0000 - val_loss: 0.9146 - val_accuracy: 0.9375\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 1s 595ms/step - loss: 3.3266e-06 - accuracy: 1.0000 - val_loss: 0.9126 - val_accuracy: 0.8125\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 1s 595ms/step - loss: 1.9878e-04 - accuracy: 1.0000 - val_loss: 1.2546 - val_accuracy: 0.7812\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 1s 616ms/step - loss: 1.5730e-05 - accuracy: 1.0000 - val_loss: 1.0841 - val_accuracy: 0.8125\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 1s 601ms/step - loss: 2.9624e-05 - accuracy: 1.0000 - val_loss: 1.2767 - val_accuracy: 0.8125\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 1s 599ms/step - loss: 3.0739e-04 - accuracy: 1.0000 - val_loss: 1.3069 - val_accuracy: 0.7812\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 1s 604ms/step - loss: 1.3734e-05 - accuracy: 1.0000 - val_loss: 0.7651 - val_accuracy: 0.8750\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 1s 618ms/step - loss: 1.0391e-05 - accuracy: 1.0000 - val_loss: 1.3900 - val_accuracy: 0.8125\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 1s 596ms/step - loss: 7.6418e-06 - accuracy: 1.0000 - val_loss: 0.7186 - val_accuracy: 0.8438\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 1s 598ms/step - loss: 6.3829e-06 - accuracy: 1.0000 - val_loss: 0.5700 - val_accuracy: 0.8438\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 1s 608ms/step - loss: 6.2842e-06 - accuracy: 1.0000 - val_loss: 0.9252 - val_accuracy: 0.7812\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 1s 592ms/step - loss: 9.2140e-06 - accuracy: 1.0000 - val_loss: 1.3749 - val_accuracy: 0.8438\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 1s 585ms/step - loss: 3.1254e-05 - accuracy: 1.0000 - val_loss: 0.9049 - val_accuracy: 0.8438\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 1s 610ms/step - loss: 7.1857e-06 - accuracy: 1.0000 - val_loss: 0.9579 - val_accuracy: 0.8438\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 1s 601ms/step - loss: 3.9349e-05 - accuracy: 1.0000 - val_loss: 0.7044 - val_accuracy: 0.8438\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 1s 588ms/step - loss: 5.9911e-06 - accuracy: 1.0000 - val_loss: 0.9436 - val_accuracy: 0.8125\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1139634fa0>"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications import MobileNetV2"
      ],
      "metadata": {
        "id": "uzCduyc7tdw5"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mobilenet = MobileNetV2(input_shape=image_size+[3],weights=\"imagenet\",include_top=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTo462zIxJOp",
        "outputId": "c5cc3447-22d0-48d7-fb6d-f4279ea09af7"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9406464/9406464 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in mobilenet.layers:\n",
        "  layer.trainable = False"
      ],
      "metadata": {
        "id": "zYDrVVnsxoVb"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = Flatten()(mobilenet.output)\n",
        "dense = Dense(50,activation=\"relu\")(x)\n",
        "dense2 = Dense(20,activation=\"relu\")(dense)\n",
        "model_mobilenet = Dense(3,activation=\"softmax\")(dense2)"
      ],
      "metadata": {
        "id": "Ces-p9vDx2at"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(inputs=mobilenet.input,outputs=model_mobilenet)"
      ],
      "metadata": {
        "id": "KsF3DdKdyAsn"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tP31tG60yO0b",
        "outputId": "62b3eca8-3930-4fe2-b0f7-938b7f9a9156"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_8 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " Conv1 (Conv2D)                 (None, 112, 112, 32  864         ['input_8[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " bn_Conv1 (BatchNormalization)  (None, 112, 112, 32  128         ['Conv1[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " Conv1_relu (ReLU)              (None, 112, 112, 32  0           ['bn_Conv1[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise (Depth  (None, 112, 112, 32  288        ['Conv1_relu[0][0]']             \n",
            " wiseConv2D)                    )                                                                 \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise_BN (Ba  (None, 112, 112, 32  128        ['expanded_conv_depthwise[0][0]']\n",
            " tchNormalization)              )                                                                 \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise_relu (  (None, 112, 112, 32  0          ['expanded_conv_depthwise_BN[0][0\n",
            " ReLU)                          )                                ]']                              \n",
            "                                                                                                  \n",
            " expanded_conv_project (Conv2D)  (None, 112, 112, 16  512        ['expanded_conv_depthwise_relu[0]\n",
            "                                )                                [0]']                            \n",
            "                                                                                                  \n",
            " expanded_conv_project_BN (Batc  (None, 112, 112, 16  64         ['expanded_conv_project[0][0]']  \n",
            " hNormalization)                )                                                                 \n",
            "                                                                                                  \n",
            " block_1_expand (Conv2D)        (None, 112, 112, 96  1536        ['expanded_conv_project_BN[0][0]'\n",
            "                                )                                ]                                \n",
            "                                                                                                  \n",
            " block_1_expand_BN (BatchNormal  (None, 112, 112, 96  384        ['block_1_expand[0][0]']         \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " block_1_expand_relu (ReLU)     (None, 112, 112, 96  0           ['block_1_expand_BN[0][0]']      \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block_1_pad (ZeroPadding2D)    (None, 113, 113, 96  0           ['block_1_expand_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block_1_depthwise (DepthwiseCo  (None, 56, 56, 96)  864         ['block_1_pad[0][0]']            \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_1_depthwise_BN (BatchNor  (None, 56, 56, 96)  384         ['block_1_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_1_depthwise_relu (ReLU)  (None, 56, 56, 96)   0           ['block_1_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_1_project (Conv2D)       (None, 56, 56, 24)   2304        ['block_1_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_1_project_BN (BatchNorma  (None, 56, 56, 24)  96          ['block_1_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_2_expand (Conv2D)        (None, 56, 56, 144)  3456        ['block_1_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_2_expand_BN (BatchNormal  (None, 56, 56, 144)  576        ['block_2_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_2_expand_relu (ReLU)     (None, 56, 56, 144)  0           ['block_2_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_2_depthwise (DepthwiseCo  (None, 56, 56, 144)  1296       ['block_2_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_2_depthwise_BN (BatchNor  (None, 56, 56, 144)  576        ['block_2_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_2_depthwise_relu (ReLU)  (None, 56, 56, 144)  0           ['block_2_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_2_project (Conv2D)       (None, 56, 56, 24)   3456        ['block_2_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_2_project_BN (BatchNorma  (None, 56, 56, 24)  96          ['block_2_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_2_add (Add)              (None, 56, 56, 24)   0           ['block_1_project_BN[0][0]',     \n",
            "                                                                  'block_2_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_3_expand (Conv2D)        (None, 56, 56, 144)  3456        ['block_2_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_3_expand_BN (BatchNormal  (None, 56, 56, 144)  576        ['block_3_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_3_expand_relu (ReLU)     (None, 56, 56, 144)  0           ['block_3_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_3_pad (ZeroPadding2D)    (None, 57, 57, 144)  0           ['block_3_expand_relu[0][0]']    \n",
            "                                                                                                  \n",
            " block_3_depthwise (DepthwiseCo  (None, 28, 28, 144)  1296       ['block_3_pad[0][0]']            \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_3_depthwise_BN (BatchNor  (None, 28, 28, 144)  576        ['block_3_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_3_depthwise_relu (ReLU)  (None, 28, 28, 144)  0           ['block_3_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_3_project (Conv2D)       (None, 28, 28, 32)   4608        ['block_3_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_3_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_3_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_4_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_3_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_4_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_4_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_4_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_4_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_4_depthwise (DepthwiseCo  (None, 28, 28, 192)  1728       ['block_4_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_4_depthwise_BN (BatchNor  (None, 28, 28, 192)  768        ['block_4_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_4_depthwise_relu (ReLU)  (None, 28, 28, 192)  0           ['block_4_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_4_project (Conv2D)       (None, 28, 28, 32)   6144        ['block_4_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_4_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_4_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_4_add (Add)              (None, 28, 28, 32)   0           ['block_3_project_BN[0][0]',     \n",
            "                                                                  'block_4_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_5_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_4_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_5_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_5_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_5_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_5_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_5_depthwise (DepthwiseCo  (None, 28, 28, 192)  1728       ['block_5_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_5_depthwise_BN (BatchNor  (None, 28, 28, 192)  768        ['block_5_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_5_depthwise_relu (ReLU)  (None, 28, 28, 192)  0           ['block_5_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_5_project (Conv2D)       (None, 28, 28, 32)   6144        ['block_5_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_5_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_5_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_5_add (Add)              (None, 28, 28, 32)   0           ['block_4_add[0][0]',            \n",
            "                                                                  'block_5_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_6_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_5_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_6_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_6_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_6_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_6_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_6_pad (ZeroPadding2D)    (None, 29, 29, 192)  0           ['block_6_expand_relu[0][0]']    \n",
            "                                                                                                  \n",
            " block_6_depthwise (DepthwiseCo  (None, 14, 14, 192)  1728       ['block_6_pad[0][0]']            \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_6_depthwise_BN (BatchNor  (None, 14, 14, 192)  768        ['block_6_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_6_depthwise_relu (ReLU)  (None, 14, 14, 192)  0           ['block_6_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_6_project (Conv2D)       (None, 14, 14, 64)   12288       ['block_6_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_6_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_6_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_7_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_6_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_7_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_7_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_7_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_7_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_7_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_7_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_7_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_7_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_7_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_7_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_7_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_7_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_7_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_7_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_7_add (Add)              (None, 14, 14, 64)   0           ['block_6_project_BN[0][0]',     \n",
            "                                                                  'block_7_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_8_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_7_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_8_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_8_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_8_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_8_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_8_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_8_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_8_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_8_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_8_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_8_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_8_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_8_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_8_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_8_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_8_add (Add)              (None, 14, 14, 64)   0           ['block_7_add[0][0]',            \n",
            "                                                                  'block_8_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_9_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_8_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_9_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_9_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_9_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_9_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_9_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_9_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_9_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_9_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_9_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_9_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_9_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_9_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_9_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_9_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_9_add (Add)              (None, 14, 14, 64)   0           ['block_8_add[0][0]',            \n",
            "                                                                  'block_9_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_10_expand (Conv2D)       (None, 14, 14, 384)  24576       ['block_9_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_10_expand_BN (BatchNorma  (None, 14, 14, 384)  1536       ['block_10_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_10_expand_relu (ReLU)    (None, 14, 14, 384)  0           ['block_10_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_10_depthwise (DepthwiseC  (None, 14, 14, 384)  3456       ['block_10_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_10_depthwise_BN (BatchNo  (None, 14, 14, 384)  1536       ['block_10_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_10_depthwise_relu (ReLU)  (None, 14, 14, 384)  0          ['block_10_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_10_project (Conv2D)      (None, 14, 14, 96)   36864       ['block_10_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_10_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_10_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_11_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_10_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_11_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_11_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_11_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_11_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_11_depthwise (DepthwiseC  (None, 14, 14, 576)  5184       ['block_11_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_11_depthwise_BN (BatchNo  (None, 14, 14, 576)  2304       ['block_11_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_11_depthwise_relu (ReLU)  (None, 14, 14, 576)  0          ['block_11_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_11_project (Conv2D)      (None, 14, 14, 96)   55296       ['block_11_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_11_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_11_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_11_add (Add)             (None, 14, 14, 96)   0           ['block_10_project_BN[0][0]',    \n",
            "                                                                  'block_11_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_12_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_11_add[0][0]']           \n",
            "                                                                                                  \n",
            " block_12_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_12_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_12_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_12_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_12_depthwise (DepthwiseC  (None, 14, 14, 576)  5184       ['block_12_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_12_depthwise_BN (BatchNo  (None, 14, 14, 576)  2304       ['block_12_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_12_depthwise_relu (ReLU)  (None, 14, 14, 576)  0          ['block_12_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_12_project (Conv2D)      (None, 14, 14, 96)   55296       ['block_12_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_12_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_12_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_12_add (Add)             (None, 14, 14, 96)   0           ['block_11_add[0][0]',           \n",
            "                                                                  'block_12_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_13_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_12_add[0][0]']           \n",
            "                                                                                                  \n",
            " block_13_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_13_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_13_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_13_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_13_pad (ZeroPadding2D)   (None, 15, 15, 576)  0           ['block_13_expand_relu[0][0]']   \n",
            "                                                                                                  \n",
            " block_13_depthwise (DepthwiseC  (None, 7, 7, 576)   5184        ['block_13_pad[0][0]']           \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_13_depthwise_BN (BatchNo  (None, 7, 7, 576)   2304        ['block_13_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_13_depthwise_relu (ReLU)  (None, 7, 7, 576)   0           ['block_13_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_13_project (Conv2D)      (None, 7, 7, 160)    92160       ['block_13_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_13_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_13_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_14_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_13_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_14_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_14_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_14_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_14_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_14_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_14_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_14_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_14_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_14_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_14_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_14_project (Conv2D)      (None, 7, 7, 160)    153600      ['block_14_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_14_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_14_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_14_add (Add)             (None, 7, 7, 160)    0           ['block_13_project_BN[0][0]',    \n",
            "                                                                  'block_14_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_15_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_14_add[0][0]']           \n",
            "                                                                                                  \n",
            " block_15_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_15_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_15_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_15_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_15_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_15_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_15_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_15_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_15_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_15_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_15_project (Conv2D)      (None, 7, 7, 160)    153600      ['block_15_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_15_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_15_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_15_add (Add)             (None, 7, 7, 160)    0           ['block_14_add[0][0]',           \n",
            "                                                                  'block_15_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_16_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_15_add[0][0]']           \n",
            "                                                                                                  \n",
            " block_16_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_16_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_16_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_16_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_16_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_16_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_16_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_16_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_16_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_16_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_16_project (Conv2D)      (None, 7, 7, 320)    307200      ['block_16_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_16_project_BN (BatchNorm  (None, 7, 7, 320)   1280        ['block_16_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " Conv_1 (Conv2D)                (None, 7, 7, 1280)   409600      ['block_16_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " Conv_1_bn (BatchNormalization)  (None, 7, 7, 1280)  5120        ['Conv_1[0][0]']                 \n",
            "                                                                                                  \n",
            " out_relu (ReLU)                (None, 7, 7, 1280)   0           ['Conv_1_bn[0][0]']              \n",
            "                                                                                                  \n",
            " flatten_7 (Flatten)            (None, 62720)        0           ['out_relu[0][0]']               \n",
            "                                                                                                  \n",
            " dense_17 (Dense)               (None, 50)           3136050     ['flatten_7[0][0]']              \n",
            "                                                                                                  \n",
            " dense_18 (Dense)               (None, 20)           1020        ['dense_17[0][0]']               \n",
            "                                                                                                  \n",
            " dense_19 (Dense)               (None, 3)            63          ['dense_18[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5,395,117\n",
            "Trainable params: 3,137,133\n",
            "Non-trainable params: 2,257,984\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "LKW8Xb5ZyTUW"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(training_set,validation_data=test_set,epochs=100,steps_per_epoch=steps_per,validation_steps=val_step)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDrhQPQvyaFY",
        "outputId": "8232b27f-fa18-4dd4-bcba-3a1dfd0ed9e7"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 1s 689ms/step - loss: 1.2628e-06 - accuracy: 1.0000 - val_loss: 0.9461 - val_accuracy: 0.8125\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 1s 580ms/step - loss: 1.1399e-06 - accuracy: 1.0000 - val_loss: 2.5607 - val_accuracy: 0.8750\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 1s 591ms/step - loss: 7.7485e-07 - accuracy: 1.0000 - val_loss: 2.4710 - val_accuracy: 0.8750\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 1s 579ms/step - loss: 3.7426e-04 - accuracy: 1.0000 - val_loss: 2.7855 - val_accuracy: 0.8750\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 1s 587ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 1.2355 - val_accuracy: 0.8750\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 1s 587ms/step - loss: 4.1909e-07 - accuracy: 1.0000 - val_loss: 2.5156 - val_accuracy: 0.8125\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 1s 582ms/step - loss: 1.3366e-05 - accuracy: 1.0000 - val_loss: 2.0532 - val_accuracy: 0.8438\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 1s 582ms/step - loss: 8.5493e-07 - accuracy: 1.0000 - val_loss: 1.5771 - val_accuracy: 0.7812\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 1s 580ms/step - loss: 3.7253e-09 - accuracy: 1.0000 - val_loss: 2.8121 - val_accuracy: 0.8125\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 1s 588ms/step - loss: 1.9371e-07 - accuracy: 1.0000 - val_loss: 2.6588 - val_accuracy: 0.8438\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 1s 575ms/step - loss: 2.7304e-06 - accuracy: 1.0000 - val_loss: 1.3789 - val_accuracy: 0.8438\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 1s 575ms/step - loss: 7.4506e-09 - accuracy: 1.0000 - val_loss: 1.7181 - val_accuracy: 0.8125\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 1s 589ms/step - loss: 1.6018e-06 - accuracy: 1.0000 - val_loss: 3.2700 - val_accuracy: 0.7500\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 1s 586ms/step - loss: 1.2846e-05 - accuracy: 1.0000 - val_loss: 2.3434 - val_accuracy: 0.8438\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 1s 573ms/step - loss: 1.0776e-04 - accuracy: 1.0000 - val_loss: 1.9368 - val_accuracy: 0.8438\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 1s 592ms/step - loss: 8.7068e-05 - accuracy: 1.0000 - val_loss: 2.5423 - val_accuracy: 0.7812\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 1s 592ms/step - loss: 1.1966e-05 - accuracy: 1.0000 - val_loss: 5.2333 - val_accuracy: 0.6562\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 1s 570ms/step - loss: 0.0479 - accuracy: 0.9844 - val_loss: 2.9139 - val_accuracy: 0.7812\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 1s 581ms/step - loss: 4.6146e-04 - accuracy: 1.0000 - val_loss: 2.4856 - val_accuracy: 0.8750\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 1s 575ms/step - loss: 1.4435e-06 - accuracy: 1.0000 - val_loss: 1.9999 - val_accuracy: 0.8750\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 1s 566ms/step - loss: 3.7625e-07 - accuracy: 1.0000 - val_loss: 1.9392 - val_accuracy: 0.8750\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 1s 584ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 4.3505 - val_accuracy: 0.8125\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 1s 581ms/step - loss: 0.0778 - accuracy: 0.9688 - val_loss: 2.1538 - val_accuracy: 0.8438\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 1s 593ms/step - loss: 2.2890e-04 - accuracy: 1.0000 - val_loss: 1.3852 - val_accuracy: 0.8125\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 1s 574ms/step - loss: 9.4249e-07 - accuracy: 1.0000 - val_loss: 1.8318 - val_accuracy: 0.7500\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 1s 568ms/step - loss: 0.0503 - accuracy: 0.9844 - val_loss: 2.9981 - val_accuracy: 0.7500\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 1s 600ms/step - loss: 1.5657e-04 - accuracy: 1.0000 - val_loss: 2.8329 - val_accuracy: 0.7500\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 1s 580ms/step - loss: 0.0743 - accuracy: 0.9688 - val_loss: 1.2832 - val_accuracy: 0.7812\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 1s 584ms/step - loss: 5.4303e-04 - accuracy: 1.0000 - val_loss: 0.5492 - val_accuracy: 0.8750\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 1s 578ms/step - loss: 8.7610e-04 - accuracy: 1.0000 - val_loss: 0.8275 - val_accuracy: 0.8750\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 1s 595ms/step - loss: 0.0336 - accuracy: 0.9844 - val_loss: 2.4456 - val_accuracy: 0.8438\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 1s 577ms/step - loss: 0.0315 - accuracy: 0.9844 - val_loss: 1.0724 - val_accuracy: 0.8750\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 1s 578ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.6370 - val_accuracy: 0.8125\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 1s 597ms/step - loss: 7.8200e-04 - accuracy: 1.0000 - val_loss: 2.2424 - val_accuracy: 0.7812\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 1s 585ms/step - loss: 0.0656 - accuracy: 0.9844 - val_loss: 3.2488 - val_accuracy: 0.7188\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 1s 595ms/step - loss: 2.5591e-04 - accuracy: 1.0000 - val_loss: 2.9542 - val_accuracy: 0.7500\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 1s 581ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 3.7517 - val_accuracy: 0.6875\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 1s 600ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 3.7774 - val_accuracy: 0.7812\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 1s 626ms/step - loss: 3.6428e-04 - accuracy: 1.0000 - val_loss: 5.6441 - val_accuracy: 0.6875\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 1s 595ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 3.6513 - val_accuracy: 0.7500\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 1s 594ms/step - loss: 3.5769e-05 - accuracy: 1.0000 - val_loss: 2.4649 - val_accuracy: 0.7188\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 1s 590ms/step - loss: 0.0477 - accuracy: 0.9844 - val_loss: 4.0814 - val_accuracy: 0.7500\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 1s 578ms/step - loss: 3.3528e-08 - accuracy: 1.0000 - val_loss: 2.4110 - val_accuracy: 0.8750\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 1s 582ms/step - loss: 4.0866e-05 - accuracy: 1.0000 - val_loss: 3.5883 - val_accuracy: 0.7188\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 1s 577ms/step - loss: 6.0535e-07 - accuracy: 1.0000 - val_loss: 5.4716 - val_accuracy: 0.7188\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 1s 587ms/step - loss: 0.0230 - accuracy: 0.9844 - val_loss: 2.7583 - val_accuracy: 0.8438\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 1s 581ms/step - loss: 5.3749e-06 - accuracy: 1.0000 - val_loss: 3.4657 - val_accuracy: 0.8125\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 1s 605ms/step - loss: 2.9988e-07 - accuracy: 1.0000 - val_loss: 1.1433 - val_accuracy: 0.9062\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 1s 578ms/step - loss: 7.9699e-04 - accuracy: 1.0000 - val_loss: 4.3816 - val_accuracy: 0.8125\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 1s 578ms/step - loss: 2.6578e-06 - accuracy: 1.0000 - val_loss: 2.5362 - val_accuracy: 0.7812\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 1s 594ms/step - loss: 7.6367e-07 - accuracy: 1.0000 - val_loss: 2.2095 - val_accuracy: 0.8438\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 1s 583ms/step - loss: 1.2293e-07 - accuracy: 1.0000 - val_loss: 2.9963 - val_accuracy: 0.8125\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 1s 607ms/step - loss: 1.2535e-06 - accuracy: 1.0000 - val_loss: 2.5165 - val_accuracy: 0.8438\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 1s 579ms/step - loss: 0.0264 - accuracy: 0.9844 - val_loss: 1.8690 - val_accuracy: 0.8438\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 1s 588ms/step - loss: 1.3858e-05 - accuracy: 1.0000 - val_loss: 4.1787 - val_accuracy: 0.7812\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 1s 586ms/step - loss: 8.3181e-04 - accuracy: 1.0000 - val_loss: 4.1949 - val_accuracy: 0.7500\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 1s 596ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 3.1273 - val_accuracy: 0.8125\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 1s 581ms/step - loss: 0.0391 - accuracy: 0.9844 - val_loss: 4.7559 - val_accuracy: 0.7500\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 1s 586ms/step - loss: 8.8124e-05 - accuracy: 1.0000 - val_loss: 3.3371 - val_accuracy: 0.7188\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 1s 576ms/step - loss: 0.0450 - accuracy: 0.9844 - val_loss: 1.2534 - val_accuracy: 0.8750\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 1s 581ms/step - loss: 5.4017e-08 - accuracy: 1.0000 - val_loss: 3.1121 - val_accuracy: 0.7188\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 1s 573ms/step - loss: 4.9314e-05 - accuracy: 1.0000 - val_loss: 1.4618 - val_accuracy: 0.8438\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 1s 582ms/step - loss: 2.3767e-05 - accuracy: 1.0000 - val_loss: 3.1198 - val_accuracy: 0.8125\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 1s 599ms/step - loss: 4.0191e-06 - accuracy: 1.0000 - val_loss: 3.6949 - val_accuracy: 0.7812\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 1s 577ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.5878 - val_accuracy: 0.8125\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 1s 574ms/step - loss: 0.0387 - accuracy: 0.9844 - val_loss: 3.8292 - val_accuracy: 0.8125\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 1s 586ms/step - loss: 7.7112e-07 - accuracy: 1.0000 - val_loss: 2.0607 - val_accuracy: 0.8438\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 1s 572ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.4701 - val_accuracy: 0.7812\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 1s 566ms/step - loss: 2.9067e-04 - accuracy: 1.0000 - val_loss: 4.6393 - val_accuracy: 0.8125\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 1s 572ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.5050 - val_accuracy: 0.7812\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 1s 574ms/step - loss: 9.7041e-07 - accuracy: 1.0000 - val_loss: 5.4105 - val_accuracy: 0.7188\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 1s 593ms/step - loss: 5.5879e-09 - accuracy: 1.0000 - val_loss: 4.4394 - val_accuracy: 0.7812\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 1s 569ms/step - loss: 0.0229 - accuracy: 0.9844 - val_loss: 2.9248 - val_accuracy: 0.8125\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 1s 593ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.4093 - val_accuracy: 0.7812\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 1s 564ms/step - loss: 5.1252e-06 - accuracy: 1.0000 - val_loss: 4.1734 - val_accuracy: 0.7500\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 1s 570ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.5233 - val_accuracy: 0.7812\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 1s 591ms/step - loss: 6.5377e-07 - accuracy: 1.0000 - val_loss: 1.1948 - val_accuracy: 0.8750\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 1s 566ms/step - loss: 1.8626e-09 - accuracy: 1.0000 - val_loss: 2.6626 - val_accuracy: 0.7812\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 1s 567ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.4406 - val_accuracy: 0.7812\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 1s 598ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.4637 - val_accuracy: 0.7500\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 1s 591ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8334 - val_accuracy: 0.7812\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 1s 595ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.3096 - val_accuracy: 0.8125\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 1s 591ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.1137 - val_accuracy: 0.7812\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 1s 605ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.2162 - val_accuracy: 0.8438\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 1s 619ms/step - loss: 1.3039e-08 - accuracy: 1.0000 - val_loss: 1.5019 - val_accuracy: 0.8438\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 1s 649ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8500 - val_accuracy: 0.7812\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 1s 586ms/step - loss: 1.1548e-07 - accuracy: 1.0000 - val_loss: 2.3219 - val_accuracy: 0.7812\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 1s 592ms/step - loss: 9.8466e-06 - accuracy: 1.0000 - val_loss: 1.9585 - val_accuracy: 0.7812\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 1s 581ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8501 - val_accuracy: 0.7500\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 1s 580ms/step - loss: 3.7253e-09 - accuracy: 1.0000 - val_loss: 1.2459 - val_accuracy: 0.8438\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 1s 582ms/step - loss: 2.0489e-08 - accuracy: 1.0000 - val_loss: 3.8332 - val_accuracy: 0.7188\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 1s 587ms/step - loss: 2.4633e-05 - accuracy: 1.0000 - val_loss: 3.2029 - val_accuracy: 0.7500\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 1s 598ms/step - loss: 1.8626e-09 - accuracy: 1.0000 - val_loss: 1.6313 - val_accuracy: 0.8750\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 1s 604ms/step - loss: 3.1665e-08 - accuracy: 1.0000 - val_loss: 1.7193 - val_accuracy: 0.8438\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 1s 582ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.6533 - val_accuracy: 0.7812\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 1s 591ms/step - loss: 9.3132e-09 - accuracy: 1.0000 - val_loss: 2.5386 - val_accuracy: 0.7812\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 1s 591ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6274 - val_accuracy: 0.8125\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 1s 588ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8603 - val_accuracy: 0.8125\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 1s 595ms/step - loss: 9.1764e-06 - accuracy: 1.0000 - val_loss: 2.2058 - val_accuracy: 0.8125\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 1s 590ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.7398 - val_accuracy: 0.7812\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1139c9c9a0>"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DR-FVKOtyfDr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}